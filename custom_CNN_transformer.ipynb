{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torchvision import datasets, transforms\n",
        "from typing import List, Tuple, Optional\n",
        "from dataclasses import dataclass\n",
        "import math"
      ],
      "metadata": {
        "id": "KqVJ4N1Ha6Yi"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# 1. Custom Layer Implementations\n",
        "# --------------------------------------------------------------------------------\n",
        "class CustomReLU:\n",
        "    \"\"\"Custom ReLU activation\"\"\"\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        return torch.maximum(x, torch.tensor(0.))"
      ],
      "metadata": {
        "id": "d4xlwZWAwsO_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomConv2d:\n",
        "    def __init__(self, in_channels: int, out_channels: int, kernel_size: int,\n",
        "                 stride: int = 1, padding: int = 0):\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride\n",
        "        self.padding = padding\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "        # Initialize weights and bias using Kaiming initialization\n",
        "        # k = 1 / (in_channels * kernel_size * kernel_size)\n",
        "        # self.weight = torch.randn(out_channels, in_channels, kernel_size, kernel_size) * math.sqrt(2./k)\n",
        "        fan_in = in_channels * kernel_size * kernel_size\n",
        "        bound = math.sqrt(2. / fan_in)\n",
        "        self.weight = torch.randn(out_channels, in_channels, kernel_size, kernel_size) * bound\n",
        "        self.weight.requires_grad = True\n",
        "        self.bias = torch.zeros(out_channels)\n",
        "        self.bias.requires_grad = True\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        self.weight = self.weight.to(device)\n",
        "        self.bias = self.bias.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Ensure input and weights are on the same device\n",
        "        if x.device != self.weight.device:\n",
        "            x = x.to(self.weight.device)\n",
        "\n",
        "        batch_size, in_channels, height, width = x.shape\n",
        "\n",
        "        # Add padding if needed\n",
        "        if self.padding > 0:\n",
        "            x = torch.nn.functional.pad(x, (self.padding, self.padding,\n",
        "                                          self.padding, self.padding))\n",
        "\n",
        "        # Calculate output dimensions\n",
        "        out_height = (height + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
        "        out_width = (width + 2 * self.padding - self.kernel_size) // self.stride + 1\n",
        "\n",
        "        # Extract patches\n",
        "        patches = x.unfold(2, self.kernel_size, self.stride)  # unfold height\n",
        "        patches = patches.unfold(3, self.kernel_size, self.stride)  # unfold width\n",
        "\n",
        "        # Reshape patches to [batch_size, out_height * out_width, in_channels * kernel_size * kernel_size]\n",
        "        patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()\n",
        "        patches = patches.reshape(batch_size, out_height * out_width, -1)\n",
        "\n",
        "        # Reshape weight to [out_channels, in_channels * kernel_size * kernel_size]\n",
        "        weight = self.weight.reshape(self.out_channels, -1)\n",
        "\n",
        "        # Perform convolution using batch matrix multiplication\n",
        "        output = torch.matmul(patches, weight.t())  # [batch_size, out_height * out_width, out_channels]\n",
        "\n",
        "        # Reshape output and add bias\n",
        "        output = output.reshape(batch_size, out_height, out_width, self.out_channels)\n",
        "        output = output.permute(0, 3, 1, 2).contiguous()  # [batch_size, out_channels, out_height, out_width]\n",
        "        output = output + self.bias.view(1, -1, 1, 1)\n",
        "\n",
        "        return output\n",
        "\n",
        "class CustomMaxPool2d:\n",
        "    def __init__(self, kernel_size: int, stride: Optional[int] = None):\n",
        "        self.kernel_size = kernel_size\n",
        "        self.stride = stride if stride is not None else kernel_size\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Extract patches\n",
        "        patches = x.unfold(2, self.kernel_size, self.stride)  # unfold height\n",
        "        patches = patches.unfold(3, self.kernel_size, self.stride)  # unfold width\n",
        "\n",
        "        # Get max values\n",
        "        pooled = patches.max(dim=4)[0].max(dim=4)[0]\n",
        "        return pooled"
      ],
      "metadata": {
        "id": "U86WGCXGy3Kv"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomLinear:\n",
        "    def __init__(self, in_features: int, out_features: int):\n",
        "        self.in_features = in_features\n",
        "        self.out_features = out_features\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "        # Initialize weights and bias\n",
        "        k = 1 / in_features\n",
        "        self.weight = torch.randn(out_features, in_features) * math.sqrt(k)\n",
        "        self.weight.requires_grad = True\n",
        "        self.bias = torch.zeros(out_features)\n",
        "        self.bias.requires_grad = True\n",
        "\n",
        "    def to(self, device):\n",
        "        self.device = device\n",
        "        self.weight = self.weight.to(device)\n",
        "        self.bias = self.bias.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Ensure input and weights are on the same device\n",
        "        if x.device != self.weight.device:\n",
        "            x = x.to(self.weight.device)\n",
        "        return torch.matmul(x, self.weight.t()) + self.bias"
      ],
      "metadata": {
        "id": "qhwzW6XKxpwn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# 2. Custom CNN Model\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "class CustomCNN:\n",
        "    \"\"\"Custom CNN implementation for MNIST\"\"\"\n",
        "\n",
        "    def __init__(self):\n",
        "        # Define layers with better architecture\n",
        "        self.conv1 = CustomConv2d(1, 16, kernel_size=3, padding=1)  # Changed to 16 filters\n",
        "        self.conv2 = CustomConv2d(16, 32, kernel_size=3, padding=1)  # Changed to 32 filters\n",
        "        self.conv3 = CustomConv2d(32, 64, kernel_size=3, padding=1)  # Added third conv layer\n",
        "        self.pool = CustomMaxPool2d(kernel_size=2)\n",
        "        self.relu = CustomReLU()\n",
        "\n",
        "        # Calculate input size for first FC layer\n",
        "        self.fc1 = CustomLinear(64 * 3 * 3, 128)  # Adjusted size due to three pooling layers\n",
        "        self.fc2 = CustomLinear(128, 10)\n",
        "        self.training = True\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move model to specified device\"\"\"\n",
        "        # Move weights and biases to device\n",
        "        for attr in self.__dict__.values():\n",
        "            if hasattr(attr, 'weight'):\n",
        "                attr.weight = attr.weight.to(device)\n",
        "            if hasattr(attr, 'bias'):\n",
        "                attr.bias = attr.bias.to(device)\n",
        "        return self\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Set the model to training mode\"\"\"\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Set the model to evaluation mode\"\"\"\n",
        "        self.training = False\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # First conv block\n",
        "        x = self.conv1.forward(x)\n",
        "        x = self.relu.forward(x)\n",
        "        x = self.pool.forward(x)  # 28x28 -> 14x14\n",
        "\n",
        "        # Second conv block\n",
        "        x = self.conv2.forward(x)\n",
        "        x = self.relu.forward(x)\n",
        "        x = self.pool.forward(x)  # 14x14 -> 7x7\n",
        "\n",
        "        # Third conv block\n",
        "        x = self.conv3.forward(x)\n",
        "        x = self.relu.forward(x)\n",
        "        x = self.pool.forward(x)  # 7x7 -> 3x3\n",
        "\n",
        "        # Flatten and fully connected layers\n",
        "        x = x.reshape(x.size(0), -1)  # Flatten\n",
        "        x = self.fc1.forward(x)\n",
        "        x = self.relu.forward(x)\n",
        "        x = self.fc2.forward(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "XDXACO7YjcFH"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cLQOIZ--dpqm"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# 3. Custom Transformer Components\n",
        "# --------------------------------------------------------------------------------\n",
        "class CustomLayerNorm:\n",
        "    \"\"\"Custom Layer Normalization implementation\"\"\"\n",
        "\n",
        "    def __init__(self, normalized_shape: int, eps: float = 1e-5):\n",
        "        self.normalized_shape = normalized_shape\n",
        "        self.eps = eps\n",
        "\n",
        "        # Learnable parameters\n",
        "        self.weight = torch.ones(normalized_shape)  # gamma\n",
        "        self.bias = torch.zeros(normalized_shape)   # beta\n",
        "        self.weight.requires_grad = True\n",
        "        self.bias.requires_grad = True\n",
        "        self.device = torch.device('cpu')\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move layer to device\"\"\"\n",
        "        self.device = device\n",
        "        self.weight = self.weight.to(device)\n",
        "        self.bias = self.bias.to(device)\n",
        "        return self\n",
        "\n",
        "    def __call__(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Make the class callable, equivalent to forward\"\"\"\n",
        "        return self.forward(x)\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            x: Input tensor of shape [..., normalized_shape]\n",
        "        Returns:\n",
        "            Normalized tensor of the same shape\n",
        "        \"\"\"\n",
        "        if x.device != self.weight.device:\n",
        "            x = x.to(self.weight.device)\n",
        "\n",
        "        # Calculate mean and variance along the last dimension\n",
        "        mean = x.mean(dim=-1, keepdim=True)\n",
        "        var = x.var(dim=-1, keepdim=True, unbiased=False)\n",
        "\n",
        "        # Normalize\n",
        "        x_norm = (x - mean) / torch.sqrt(var + self.eps)\n",
        "\n",
        "        # Scale and shift\n",
        "        return self.weight * x_norm + self.bias"
      ],
      "metadata": {
        "id": "3PMGvVkzKy3V"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTransformerEncoder:\n",
        "    \"\"\"Custom Transformer Encoder implementation\"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim: int, num_heads: int, ff_dim: int):\n",
        "        self.attention = CustomMultiHeadAttention(embed_dim, num_heads)\n",
        "        self.ff1 = CustomLinear(embed_dim, ff_dim)\n",
        "        self.ff2 = CustomLinear(ff_dim, embed_dim)\n",
        "        self.relu = CustomReLU()\n",
        "        self.training = True\n",
        "\n",
        "        # Replace PyTorch LayerNorm with custom implementation\n",
        "        self.norm1 = CustomLayerNorm(embed_dim)\n",
        "        self.norm2 = CustomLayerNorm(embed_dim)\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Set encoder to training mode\"\"\"\n",
        "        self.training = True\n",
        "        if hasattr(self.attention, 'train'):\n",
        "            self.attention.train()\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Set encoder to evaluation mode\"\"\"\n",
        "        self.training = False\n",
        "        if hasattr(self.attention, 'eval'):\n",
        "            self.attention.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move encoder to specified device\"\"\"\n",
        "        self.attention = self.attention.to(device)\n",
        "        self.ff1 = self.ff1.to(device)\n",
        "        self.ff2 = self.ff2.to(device)\n",
        "        self.norm1 = self.norm1.to(device)\n",
        "        self.norm2 = self.norm2.to(device)\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Forward pass of transformer encoder\n",
        "        Args:\n",
        "            x: Input tensor of shape [B, seq_len, embed_dim]\n",
        "        Returns:\n",
        "            Output tensor of shape [B, seq_len, embed_dim]\n",
        "        \"\"\"\n",
        "        # Self-attention block\n",
        "        residual = x\n",
        "        x = self.norm1(x)\n",
        "        x = self.attention.forward(x)\n",
        "        x = x + residual  # Residual connection\n",
        "\n",
        "        # Feed-forward block\n",
        "        residual = x\n",
        "        x = self.norm2(x)\n",
        "        x = self.ff1.forward(x)\n",
        "        x = self.relu.forward(x)\n",
        "        x = self.ff2.forward(x)\n",
        "        x = x + residual  # Residual connection\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "fy0J-5S-3Mev"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "inD-i-msAhfQ"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomMultiHeadAttention:\n",
        "    \"\"\"Custom Multi-Head Attention implementation\"\"\"\n",
        "\n",
        "    def __init__(self, embed_dim: int, num_heads: int):\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.head_dim = embed_dim // num_heads\n",
        "\n",
        "        # Initialize Q, K, V projections\n",
        "        self.q_proj = CustomLinear(embed_dim, embed_dim)\n",
        "        self.k_proj = CustomLinear(embed_dim, embed_dim)\n",
        "        self.v_proj = CustomLinear(embed_dim, embed_dim)\n",
        "        self.out_proj = CustomLinear(embed_dim, embed_dim)\n",
        "        self.training = True\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move attention module to device\"\"\"\n",
        "        # Move all projection layers to device\n",
        "        self.q_proj = self.q_proj.to(device)\n",
        "        self.k_proj = self.k_proj.to(device)\n",
        "        self.v_proj = self.v_proj.to(device)\n",
        "        self.out_proj = self.out_proj.to(device)\n",
        "        return self\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Set attention to training mode\"\"\"\n",
        "        self.training = True\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Set attention to evaluation mode\"\"\"\n",
        "        self.training = False\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        batch_size, seq_len, _ = x.shape\n",
        "\n",
        "        # Project to Q, K, V\n",
        "        q = self.q_proj.forward(x)\n",
        "        k = self.k_proj.forward(x)\n",
        "        v = self.v_proj.forward(x)\n",
        "\n",
        "        # Reshape for multi-head attention\n",
        "        q = q.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        k = k.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "        v = v.view(batch_size, seq_len, self.num_heads, self.head_dim)\n",
        "\n",
        "        # Transpose for attention computation\n",
        "        q = q.transpose(1, 2)\n",
        "        k = k.transpose(1, 2)\n",
        "        v = v.transpose(1, 2)\n",
        "\n",
        "        # Compute attention scores\n",
        "        scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(self.head_dim)\n",
        "        attn = torch.softmax(scores, dim=-1)\n",
        "\n",
        "        # Apply attention to values\n",
        "        out = torch.matmul(attn, v)\n",
        "\n",
        "        # Reshape and project output\n",
        "        out = out.transpose(1, 2).contiguous()\n",
        "        out = out.view(batch_size, seq_len, self.embed_dim)\n",
        "        out = self.out_proj.forward(out)\n",
        "\n",
        "        return out"
      ],
      "metadata": {
        "id": "--yr8nEE1zBA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E8UBfFsTAfnU"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# 4. Custom Transformer Model for MNIST\n",
        "# --------------------------------------------------------------------------------\n",
        "class CustomTransformerMNIST:\n",
        "    \"\"\"Custom Transformer implementation for MNIST\"\"\"\n",
        "\n",
        "    def __init__(self, patch_size: int = 7):\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (28 // patch_size) ** 2  # For MNIST images (28x28)\n",
        "        self.patch_dim = patch_size * patch_size\n",
        "\n",
        "        # Embedding layers\n",
        "        self.patch_embed = CustomLinear(self.patch_dim, 256)\n",
        "        self.pos_embed = torch.randn(1, self.num_patches, 256)\n",
        "\n",
        "        # Transformer layers\n",
        "        self.encoder1 = CustomTransformerEncoder(256, 8, 512)\n",
        "        self.encoder2 = CustomTransformerEncoder(256, 8, 512)\n",
        "\n",
        "        # Classification head\n",
        "        self.classifier = CustomLinear(256, 10)\n",
        "        self.training = True\n",
        "\n",
        "    def to_patches(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        \"\"\"Convert images to patches\n",
        "        Args:\n",
        "            x: Input tensor of shape [B, C, H, W]\n",
        "        Returns:\n",
        "            Tensor of shape [B, num_patches, patch_dim]\n",
        "        \"\"\"\n",
        "        B, C, H, W = x.shape\n",
        "        assert H == W == 28, f\"Expected 28x28 images, got {H}x{W}\"\n",
        "\n",
        "        # Unfold into patches\n",
        "        patches = x.unfold(2, self.patch_size, self.patch_size)  # Unfold H\n",
        "        patches = patches.unfold(3, self.patch_size, self.patch_size)  # Unfold W\n",
        "\n",
        "        # Reshape to [B, num_patches, patch_dim]\n",
        "        patches = patches.permute(0, 2, 3, 1, 4, 5).contiguous()\n",
        "        patches = patches.view(B, self.num_patches, -1)\n",
        "\n",
        "        return patches\n",
        "\n",
        "    def train(self):\n",
        "        \"\"\"Set model to training mode\"\"\"\n",
        "        self.training = True\n",
        "        if hasattr(self.encoder1, 'train'):\n",
        "            self.encoder1.train()\n",
        "        if hasattr(self.encoder2, 'train'):\n",
        "            self.encoder2.train()\n",
        "\n",
        "    def eval(self):\n",
        "        \"\"\"Set model to evaluation mode\"\"\"\n",
        "        self.training = False\n",
        "        if hasattr(self.encoder1, 'eval'):\n",
        "            self.encoder1.eval()\n",
        "        if hasattr(self.encoder2, 'eval'):\n",
        "            self.encoder2.eval()\n",
        "\n",
        "    def to(self, device):\n",
        "        \"\"\"Move model to specified device\"\"\"\n",
        "        # Move weights, biases and embeddings to device\n",
        "        self.pos_embed = self.pos_embed.to(device)\n",
        "        self.patch_embed = self.patch_embed.to(device)\n",
        "\n",
        "        # Move transformer encoders\n",
        "        self.encoder1 = self.encoder1.to(device)\n",
        "        self.encoder2 = self.encoder2.to(device)\n",
        "\n",
        "        # Move classifier\n",
        "        self.classifier = self.classifier.to(device)\n",
        "\n",
        "        return self\n",
        "\n",
        "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
        "        # Convert to patches and embed\n",
        "        x = self.to_patches(x)  # [B, num_patches, patch_dim]\n",
        "        x = self.patch_embed.forward(x)  # [B, num_patches, embed_dim]\n",
        "\n",
        "        # Add positional embeddings\n",
        "        x = x + self.pos_embed\n",
        "\n",
        "        # Apply transformer layers\n",
        "        x = self.encoder1.forward(x)\n",
        "        x = self.encoder2.forward(x)\n",
        "\n",
        "        # Global average pooling over patches\n",
        "        x = x.mean(dim=1)  # [B, embed_dim]\n",
        "\n",
        "        # Classification\n",
        "        x = self.classifier.forward(x)  # [B, num_classes]\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "id": "gI1ulGc4218Q"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rsCM55uK1tm0"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------------------------------------------------------------------\n",
        "# 5. Training Functions\n",
        "# --------------------------------------------------------------------------------\n",
        "\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "\n",
        "def train_epoch(model, train_loader, optimizer, criterion, epoch, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create progress bar\n",
        "    progress_bar = tqdm(enumerate(train_loader), total=len(train_loader),\n",
        "                       desc=f'Epoch {epoch}', ncols=100)\n",
        "\n",
        "    for batch_idx, (data, target) in progress_bar:\n",
        "        # Move data to device\n",
        "        data, target = data.to(device), target.to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model.forward(data)\n",
        "        loss = criterion(output, target)\n",
        "\n",
        "        # Backward pass\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Statistics\n",
        "        total_loss += loss.item()\n",
        "        pred = output.argmax(dim=1, keepdim=True)\n",
        "        batch_correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "        correct += batch_correct\n",
        "        total += target.size(0)\n",
        "\n",
        "        # Update progress bar\n",
        "        avg_loss = total_loss / (batch_idx + 1)\n",
        "        accuracy = 100. * correct / total\n",
        "        progress_bar.set_postfix({\n",
        "            'loss': f'{avg_loss:.4f}',\n",
        "            'acc': f'{accuracy:.2f}%'\n",
        "        })\n",
        "        progress_bar.update()\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Final epoch statistics\n",
        "    epoch_time = time.time() - start_time\n",
        "    avg_loss = total_loss / len(train_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'\\nEpoch {epoch} Summary:')\n",
        "    print(f'Training Loss: {avg_loss:.4f}')\n",
        "    print(f'Training Accuracy: {accuracy:.2f}% ({correct}/{total})')\n",
        "    print(f'Time: {epoch_time:.2f}s')\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate(model, test_loader, criterion, epoch, device):\n",
        "    \"\"\"Evaluate the model\"\"\"\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Create progress bar for evaluation\n",
        "    progress_bar = tqdm(enumerate(test_loader), total=len(test_loader),\n",
        "                       desc='Evaluation', ncols=100)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch_idx, (data, target) in progress_bar:\n",
        "            # Move data to device\n",
        "            data, target = data.to(device), target.to(device)\n",
        "\n",
        "            output = model.forward(data)\n",
        "            test_loss += criterion(output, target).item()\n",
        "            pred = output.argmax(dim=1, keepdim=True)\n",
        "            batch_correct = pred.eq(target.view_as(pred)).sum().item()\n",
        "            correct += batch_correct\n",
        "            total += target.size(0)\n",
        "\n",
        "            # Update progress bar\n",
        "            avg_loss = test_loss / (batch_idx + 1)\n",
        "            accuracy = 100. * correct / total\n",
        "            progress_bar.set_postfix({\n",
        "                'loss': f'{avg_loss:.4f}',\n",
        "                'acc': f'{accuracy:.2f}%'\n",
        "            })\n",
        "            progress_bar.update()\n",
        "\n",
        "    progress_bar.close()\n",
        "\n",
        "    # Final evaluation statistics\n",
        "    eval_time = time.time() - start_time\n",
        "    avg_loss = test_loss / len(test_loader)\n",
        "    accuracy = 100. * correct / total\n",
        "\n",
        "    print(f'\\nEvaluation Summary:')\n",
        "    print(f'Test Loss: {avg_loss:.4f}')\n",
        "    print(f'Test Accuracy: {accuracy:.2f}% ({correct}/{total})')\n",
        "    print(f'Time: {eval_time:.2f}s')\n",
        "\n",
        "    return avg_loss, accuracy\n",
        "\n"
      ],
      "metadata": {
        "id": "p5AKh-eOipxv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "HfRpYDQ7Add4"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # Set device\n",
        "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    print(f\"\\nUsing device: {device}\")\n",
        "\n",
        "    # Load MNIST dataset\n",
        "    print(\"\\nLoading MNIST dataset...\")\n",
        "    transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,))\n",
        "    ])\n",
        "\n",
        "    train_dataset = datasets.MNIST('./data', train=True, download=True,\n",
        "                                 transform=transform)\n",
        "    test_dataset = datasets.MNIST('./data', train=False, transform=transform)\n",
        "\n",
        "    train_loader = torch.utils.data.DataLoader(\n",
        "        train_dataset,\n",
        "        batch_size=32,  # Reduced batch size\n",
        "        shuffle=True,\n",
        "        num_workers=0,  # No multiprocessing for debugging\n",
        "        pin_memory=True\n",
        "    )\n",
        "    test_loader = torch.utils.data.DataLoader(\n",
        "        test_dataset,\n",
        "        batch_size=32,\n",
        "        num_workers=0,\n",
        "        pin_memory=True\n",
        "    )\n",
        "\n",
        "    # Initialize models and move to device\n",
        "    print(\"\\nInitializing models...\")\n",
        "    cnn_model = CustomCNN()\n",
        "    transformer_model = CustomTransformerMNIST()\n",
        "\n",
        "\n",
        "    # Get trainable parameters AFTER moving to device\n",
        "    def get_trainable_params(model):\n",
        "        params = []\n",
        "        for attr in model.__dict__.values():\n",
        "            if hasattr(attr, 'weight') and hasattr(attr, 'bias'):\n",
        "                params.extend([attr.weight, attr.bias])\n",
        "            elif isinstance(attr, (CustomTransformerEncoder, CustomMultiHeadAttention)):\n",
        "                params.extend(get_trainable_params(attr))\n",
        "        return [p for p in params if p.requires_grad]\n",
        "\n",
        "    # Get parameters\n",
        "    cnn_params = get_trainable_params(cnn_model)\n",
        "    transformer_params = get_trainable_params(transformer_model)\n",
        "\n",
        "    # Move models to device BEFORE creating optimizers\n",
        "    cnn_model = cnn_model.to(device)\n",
        "    transformer_model = transformer_model.to(device)\n",
        "\n",
        "    # Create optimizers\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "    cnn_optimizer = torch.optim.Adam(cnn_params, lr=0.001, betas=(0.9, 0.999))\n",
        "    transformer_optimizer = torch.optim.Adam(transformer_params, lr=0.001)\n",
        "\n",
        "    # Training history\n",
        "    history = {\n",
        "        'cnn': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []},\n",
        "        'transformer': {'train_loss': [], 'train_acc': [], 'test_loss': [], 'test_acc': []}\n",
        "    }\n",
        "\n",
        "    # Train CNN\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training CNN Model\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for epoch in range(1, 6):\n",
        "        print(f\"\\n{'-'*20} Epoch {epoch}/5 {'-'*20}\")\n",
        "        train_loss, train_acc = train_epoch(cnn_model, train_loader, cnn_optimizer, criterion, epoch, device)\n",
        "        test_loss, test_acc = evaluate(cnn_model, test_loader, criterion, epoch, device)\n",
        "\n",
        "        # Save history\n",
        "        history['cnn']['train_loss'].append(train_loss)\n",
        "        history['cnn']['train_acc'].append(train_acc)\n",
        "        history['cnn']['test_loss'].append(test_loss)\n",
        "        history['cnn']['test_acc'].append(test_acc)\n",
        "\n",
        "    # Train Transformer\n",
        "    print(\"\\n\" + \"=\"*60)\n",
        "    print(\"Training Transformer Model\")\n",
        "    print(\"=\"*60)\n",
        "\n",
        "    for epoch in range(1, 6):\n",
        "        print(f\"\\n{'-'*20} Epoch {epoch}/5 {'-'*20}\")\n",
        "        train_loss, train_acc = train_epoch(transformer_model, train_loader,\n",
        "                                          transformer_optimizer, criterion, epoch, device)\n",
        "        test_loss, test_acc = evaluate(transformer_model, test_loader, criterion, epoch, device)\n",
        "\n",
        "        # Save history\n",
        "        history['transformer']['train_loss'].append(train_loss)\n",
        "        history['transformer']['train_acc'].append(train_acc)\n",
        "        history['transformer']['test_loss'].append(test_loss)\n",
        "        history['transformer']['test_acc'].append(test_acc)\n",
        "\n",
        "    # Plot training history\n",
        "    plt.figure(figsize=(15, 5))\n",
        "\n",
        "    # Plot loss\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history['cnn']['train_loss'], label='CNN Train')\n",
        "    plt.plot(history['cnn']['test_loss'], label='CNN Test')\n",
        "    plt.plot(history['transformer']['train_loss'], label='Transformer Train')\n",
        "    plt.plot(history['transformer']['test_loss'], label='Transformer Test')\n",
        "    plt.title('Loss History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    # Plot accuracy\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history['cnn']['train_acc'], label='CNN Train')\n",
        "    plt.plot(history['cnn']['test_acc'], label='CNN Test')\n",
        "    plt.plot(history['transformer']['train_acc'], label='Transformer Train')\n",
        "    plt.plot(history['transformer']['test_acc'], label='Transformer Test')\n",
        "    plt.title('Accuracy History')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy (%)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('training_history.png')\n",
        "    plt.close()\n",
        "\n",
        "    print(\"\\nTraining complete! Results saved to 'training_history.png'\")"
      ],
      "metadata": {
        "id": "UQW7iJj5x0QO"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zIi8xdJDJihE",
        "outputId": "94e8737d-8afe-4130-9ac6-7d751fbc2996"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Using device: cuda\n",
            "\n",
            "Loading MNIST dataset...\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 16.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 494kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 3.84MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "<urlopen error [Errno 110] Connection timed out>\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 9.97MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
            "\n",
            "\n",
            "Initializing models...\n",
            "\n",
            "============================================================\n",
            "Training CNN Model\n",
            "============================================================\n",
            "\n",
            "-------------------- Epoch 1/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████████████████████| 1875/1875 [00:33<00:00, 55.36it/s, loss=3.4099, acc=9.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary:\n",
            "Training Loss: 3.4099\n",
            "Training Accuracy: 9.81% (5884/60000)\n",
            "Time: 33.88s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|████████████████████████| 313/313 [00:04<00:00, 77.96it/s, loss=3.4028, acc=10.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 3.4028\n",
            "Test Accuracy: 10.22% (1022/10000)\n",
            "Time: 4.02s\n",
            "\n",
            "-------------------- Epoch 2/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████████████████████| 1875/1875 [00:32<00:00, 58.29it/s, loss=3.4099, acc=9.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary:\n",
            "Training Loss: 3.4099\n",
            "Training Accuracy: 9.81% (5884/60000)\n",
            "Time: 32.18s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|████████████████████████| 313/313 [00:04<00:00, 68.67it/s, loss=3.4028, acc=10.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 3.4028\n",
            "Test Accuracy: 10.22% (1022/10000)\n",
            "Time: 4.57s\n",
            "\n",
            "-------------------- Epoch 3/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████████████████████| 1875/1875 [00:32<00:00, 58.46it/s, loss=3.4099, acc=9.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Summary:\n",
            "Training Loss: 3.4099\n",
            "Training Accuracy: 9.81% (5884/60000)\n",
            "Time: 32.08s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|████████████████████████| 313/313 [00:04<00:00, 71.11it/s, loss=3.4028, acc=10.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 3.4028\n",
            "Test Accuracy: 10.22% (1022/10000)\n",
            "Time: 4.41s\n",
            "\n",
            "-------------------- Epoch 4/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████████████████████| 1875/1875 [00:31<00:00, 59.00it/s, loss=3.4099, acc=9.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary:\n",
            "Training Loss: 3.4099\n",
            "Training Accuracy: 9.81% (5884/60000)\n",
            "Time: 31.78s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|████████████████████████| 313/313 [00:03<00:00, 83.25it/s, loss=3.4028, acc=10.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 3.4028\n",
            "Test Accuracy: 10.22% (1022/10000)\n",
            "Time: 3.77s\n",
            "\n",
            "-------------------- Epoch 5/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████████████████████| 1875/1875 [00:32<00:00, 58.38it/s, loss=3.4099, acc=9.81%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary:\n",
            "Training Loss: 3.4099\n",
            "Training Accuracy: 9.81% (5884/60000)\n",
            "Time: 32.12s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|████████████████████████| 313/313 [00:03<00:00, 83.34it/s, loss=3.4028, acc=10.22%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 3.4028\n",
            "Test Accuracy: 10.22% (1022/10000)\n",
            "Time: 3.76s\n",
            "\n",
            "============================================================\n",
            "Training Transformer Model\n",
            "============================================================\n",
            "\n",
            "-------------------- Epoch 1/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1: 100%|██████████████████████████| 1875/1875 [00:53<00:00, 34.85it/s, loss=2.6856, acc=5.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 1 Summary:\n",
            "Training Loss: 2.6856\n",
            "Training Accuracy: 5.92% (3553/60000)\n",
            "Time: 53.82s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|█████████████████████████| 313/313 [00:04<00:00, 71.59it/s, loss=2.6935, acc=5.80%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 2.6935\n",
            "Test Accuracy: 5.80% (580/10000)\n",
            "Time: 4.38s\n",
            "\n",
            "-------------------- Epoch 2/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 2: 100%|██████████████████████████| 1875/1875 [00:52<00:00, 35.64it/s, loss=2.6856, acc=5.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 2 Summary:\n",
            "Training Loss: 2.6856\n",
            "Training Accuracy: 5.92% (3553/60000)\n",
            "Time: 52.62s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|█████████████████████████| 313/313 [00:04<00:00, 78.10it/s, loss=2.6935, acc=5.80%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 2.6935\n",
            "Test Accuracy: 5.80% (580/10000)\n",
            "Time: 4.01s\n",
            "\n",
            "-------------------- Epoch 3/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 3: 100%|██████████████████████████| 1875/1875 [00:54<00:00, 34.67it/s, loss=2.6856, acc=5.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 3 Summary:\n",
            "Training Loss: 2.6856\n",
            "Training Accuracy: 5.92% (3553/60000)\n",
            "Time: 54.09s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|█████████████████████████| 313/313 [00:04<00:00, 76.20it/s, loss=2.6935, acc=5.80%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 2.6935\n",
            "Test Accuracy: 5.80% (580/10000)\n",
            "Time: 4.12s\n",
            "\n",
            "-------------------- Epoch 4/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 4: 100%|██████████████████████████| 1875/1875 [00:53<00:00, 35.21it/s, loss=2.6856, acc=5.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 4 Summary:\n",
            "Training Loss: 2.6856\n",
            "Training Accuracy: 5.92% (3553/60000)\n",
            "Time: 53.26s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|█████████████████████████| 313/313 [00:04<00:00, 66.53it/s, loss=2.6935, acc=5.80%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 2.6935\n",
            "Test Accuracy: 5.80% (580/10000)\n",
            "Time: 4.71s\n",
            "\n",
            "-------------------- Epoch 5/5 --------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 5: 100%|██████████████████████████| 1875/1875 [00:53<00:00, 35.20it/s, loss=2.6856, acc=5.92%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch 5 Summary:\n",
            "Training Loss: 2.6856\n",
            "Training Accuracy: 5.92% (3553/60000)\n",
            "Time: 53.27s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Evaluation: 100%|█████████████████████████| 313/313 [00:04<00:00, 78.23it/s, loss=2.6935, acc=5.80%]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Evaluation Summary:\n",
            "Test Loss: 2.6935\n",
            "Test Accuracy: 5.80% (580/10000)\n",
            "Time: 4.01s\n",
            "\n",
            "Training complete! Results saved to 'training_history.png'\n"
          ]
        }
      ]
    }
  ]
}